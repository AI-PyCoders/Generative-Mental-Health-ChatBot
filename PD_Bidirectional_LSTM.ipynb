{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1690459608236,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "I9Ivd53pZKzM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1690459608237,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "phybv4ljZhGs",
    "outputId": "ea41da26-ffcb-430f-ec5a-d4120347da74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-de658944-1582-4a8d-bcea-0838304ebc20\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello good morning doctor</td>\n",
       "      <td>&lt;start&gt; good morning how are you feeling today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive been feeling quite anxious lately its been...</td>\n",
       "      <td>&lt;start&gt; i see can you tell me more about what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think its mainly related to my job and the p...</td>\n",
       "      <td>&lt;start&gt; stress at work can definitely take a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a highly demanding environment and i...</td>\n",
       "      <td>&lt;start&gt; that sounds tough do you have any supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i try to talk to my friends but they dont alwa...</td>\n",
       "      <td>&lt;start&gt; having a strong support system is impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>i find it difficult to cope and the grief ofte...</td>\n",
       "      <td>&lt;start&gt; coping with grief can be emotionally e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>i havent been very open about my struggles as ...</td>\n",
       "      <td>&lt;start&gt; its common to feel hesitant about shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>lately i havent been actively practicing selfc...</td>\n",
       "      <td>&lt;start&gt; practicing selfcompassion and engaging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>i havent sought professional help yet im unsur...</td>\n",
       "      <td>&lt;start&gt; seeking professional help such as ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>thank you doctor your guidance is greatly appr...</td>\n",
       "      <td>&lt;start&gt; youre welcome its my role to provide s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1513 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de658944-1582-4a8d-bcea-0838304ebc20')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-1b9b6601-8c61-474f-b70b-f7a5618e60a3\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b9b6601-8c61-474f-b70b-f7a5618e60a3')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-1b9b6601-8c61-474f-b70b-f7a5618e60a3 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-de658944-1582-4a8d-bcea-0838304ebc20 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-de658944-1582-4a8d-bcea-0838304ebc20');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                Patient  \\\n",
       "0                             hello good morning doctor   \n",
       "1     ive been feeling quite anxious lately its been...   \n",
       "2     i think its mainly related to my job and the p...   \n",
       "3     i work in a highly demanding environment and i...   \n",
       "4     i try to talk to my friends but they dont alwa...   \n",
       "...                                                 ...   \n",
       "1508  i find it difficult to cope and the grief ofte...   \n",
       "1509  i havent been very open about my struggles as ...   \n",
       "1510  lately i havent been actively practicing selfc...   \n",
       "1511  i havent sought professional help yet im unsur...   \n",
       "1512  thank you doctor your guidance is greatly appr...   \n",
       "\n",
       "                                                 Doctor  \n",
       "0     <start> good morning how are you feeling today...  \n",
       "1     <start> i see can you tell me more about what ...  \n",
       "2     <start> stress at work can definitely take a t...  \n",
       "3     <start> that sounds tough do you have any supp...  \n",
       "4     <start> having a strong support system is impo...  \n",
       "...                                                 ...  \n",
       "1508  <start> coping with grief can be emotionally e...  \n",
       "1509  <start> its common to feel hesitant about shar...  \n",
       "1510  <start> practicing selfcompassion and engaging...  \n",
       "1511  <start> seeking professional help such as ther...  \n",
       "1512  <start> youre welcome its my role to provide s...  \n",
       "\n",
       "[1513 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/patient-doctor_old.csv')\n",
    "df['Doctor'] = df['Doctor'].apply(lambda text: '<start> ' + text + ' <end>')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5599,
     "status": "ok",
     "timestamp": 1690459613833,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "0Zz843cYZow8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(input_texts, target_texts):\n",
    "    # Create a tokenizer and fit on the input and target texts\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(input_texts + target_texts)\n",
    "    # Convert input and target texts to sequences of integers\n",
    "    encoder_input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "    decoder_input_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "    # Calculate max sequence length\n",
    "    max_sequence_length = max(max(len(seq) for seq in encoder_input_sequences),\n",
    "                             max(len(seq) for seq in decoder_input_sequences))\n",
    "    print('max sequence length:', max_sequence_length)\n",
    "    # Pad sequences to have the same length\n",
    "    encoder_input_data = pad_sequences(encoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    decoder_input_data = pad_sequences(decoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    # Shift target sequences by one time step and convert to one-hot encoding\n",
    "    decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "    decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
    "    decoder_target_data[:, -1] = tokenizer.word_index['<end>']\n",
    "    # Return preprocessed data and tokenizer\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1690459614054,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "cn5R2MR2ZvhN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Input, Embedding, Bidirectional, LSTM, Dense, Attention, Concatenate, Dot, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import vis_utils\n",
    "\n",
    "\n",
    "def create_model(vocab_size, embedding_dim, hidden_dim, max_sequence_length):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_dim, return_sequences=True, return_state=True))\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_state_h = Concatenate()([forward_h, backward_h])\n",
    "    encoder_state_c = Concatenate()([forward_c, backward_c])\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_dim*2, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])\n",
    "    decoder_outputs = Dropout(0.2)(decoder_outputs)  # Adding Dropout layer for regularization\n",
    "    # Attention mechanism\n",
    "    attention = Dot(axes=[2, 2])\n",
    "    attention_scores = attention([decoder_outputs, encoder_outputs])\n",
    "    attention_weights = Activation('softmax')(attention_scores)\n",
    "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
    "    # Concatenate the context vector and decoder outputs\n",
    "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "    # Dense layer for generating the final output\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    vis_utils.plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(model, encoder_input_data, decoder_input_data, decoder_target_data):\n",
    "    # Hyperparameters\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    validation_split = 0.2\n",
    "    patience = 8\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    # train the model\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split,\n",
    "              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1690459614661,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "hPmJB2geZtcX",
    "outputId": "9723b6c3-e1c4-4b30-a046-d3cb7761809e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sequence length: 110\n"
     ]
    }
   ],
   "source": [
    "input_texts = df['Patient'].astype(str).tolist()\n",
    "target_texts = df['Doctor'].astype(str).tolist()\n",
    "\n",
    "# Preprocess the data\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length = preprocess_data(\n",
    "    input_texts, target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6385,
     "status": "ok",
     "timestamp": 1690459621045,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "aeBcx4lUjKZQ",
    "outputId": "40d475e8-2c0e-4aac-949b-44c2463b76db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  2741\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 110)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 110, 256)     701696      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 110)]        0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  [(None, 110, 512),   1050624     ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 110, 256)     701696      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512)          0           ['bidirectional[0][1]',          \n",
      "                                                                  'bidirectional[0][3]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 512)          0           ['bidirectional[0][2]',          \n",
      "                                                                  'bidirectional[0][4]']          \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 110, 512),   1574912     ['embedding_1[0][0]',            \n",
      "                                 (None, 512),                     'concatenate[0][0]',            \n",
      "                                 (None, 512)]                     'concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 110, 512)     0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 110, 110)     0           ['dropout[0][0]',                \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 110, 110)     0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 110, 512)     0           ['activation[0][0]',             \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 110, 1024)    0           ['dot_1[0][0]',                  \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 110, 2741)    2809525     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,838,453\n",
      "Trainable params: 6,838,453\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocab size: ', vocab_size)\n",
    "\n",
    "# Create the model\n",
    "model = create_model(vocab_size, embedding_dim = 256, hidden_dim= 256, max_sequence_length = max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6082820,
     "status": "ok",
     "timestamp": 1690465703853,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "hRR4mnhVZ6rb",
    "outputId": "2979623b-5af7-4224-daa1-0bf691c9300d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 178s 4s/step - loss: 6.3030 - accuracy: 0.0436 - val_loss: 5.5855 - val_accuracy: 0.0511\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 168s 4s/step - loss: 5.6515 - accuracy: 0.0688 - val_loss: 5.2863 - val_accuracy: 0.0779\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 5.2046 - accuracy: 0.1097 - val_loss: 4.5350 - val_accuracy: 0.1742\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 167s 4s/step - loss: 4.6537 - accuracy: 0.1985 - val_loss: 3.8493 - val_accuracy: 0.2842\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 4.1295 - accuracy: 0.2671 - val_loss: 3.2728 - val_accuracy: 0.3859\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 168s 4s/step - loss: 3.7029 - accuracy: 0.3227 - val_loss: 2.7993 - val_accuracy: 0.4888\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 157s 4s/step - loss: 3.3567 - accuracy: 0.3643 - val_loss: 2.5574 - val_accuracy: 0.5279\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 3.1051 - accuracy: 0.3974 - val_loss: 2.3830 - val_accuracy: 0.5734\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 159s 4s/step - loss: 2.8707 - accuracy: 0.4261 - val_loss: 2.2479 - val_accuracy: 0.6017\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 2.6787 - accuracy: 0.4502 - val_loss: 2.1403 - val_accuracy: 0.6170\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 170s 4s/step - loss: 2.5140 - accuracy: 0.4704 - val_loss: 2.0574 - val_accuracy: 0.6335\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 167s 4s/step - loss: 2.3577 - accuracy: 0.4950 - val_loss: 1.9980 - val_accuracy: 0.6459\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 167s 4s/step - loss: 2.2298 - accuracy: 0.5128 - val_loss: 1.9386 - val_accuracy: 0.6633\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 156s 4s/step - loss: 2.1078 - accuracy: 0.5322 - val_loss: 1.9201 - val_accuracy: 0.6684\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 1.9851 - accuracy: 0.5529 - val_loss: 1.8844 - val_accuracy: 0.6751\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 159s 4s/step - loss: 1.8737 - accuracy: 0.5746 - val_loss: 1.8857 - val_accuracy: 0.6808\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 161s 4s/step - loss: 1.7717 - accuracy: 0.5919 - val_loss: 1.8509 - val_accuracy: 0.6829\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 181s 5s/step - loss: 1.6844 - accuracy: 0.6099 - val_loss: 1.8322 - val_accuracy: 0.6848\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 168s 4s/step - loss: 1.6039 - accuracy: 0.6257 - val_loss: 1.7967 - val_accuracy: 0.6940\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 1.5195 - accuracy: 0.6417 - val_loss: 1.7969 - val_accuracy: 0.6942\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 202s 5s/step - loss: 1.4500 - accuracy: 0.6553 - val_loss: 1.7958 - val_accuracy: 0.6978\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 192s 5s/step - loss: 1.3804 - accuracy: 0.6705 - val_loss: 1.8049 - val_accuracy: 0.6955\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 180s 5s/step - loss: 1.3113 - accuracy: 0.6849 - val_loss: 1.7871 - val_accuracy: 0.7007\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 179s 5s/step - loss: 1.2486 - accuracy: 0.6981 - val_loss: 1.7892 - val_accuracy: 0.6983\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 171s 5s/step - loss: 1.1931 - accuracy: 0.7104 - val_loss: 1.8030 - val_accuracy: 0.6942\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 171s 5s/step - loss: 1.1412 - accuracy: 0.7238 - val_loss: 1.7874 - val_accuracy: 0.7007\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 158s 4s/step - loss: 1.0837 - accuracy: 0.7351 - val_loss: 1.7840 - val_accuracy: 0.7041\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 166s 4s/step - loss: 1.0369 - accuracy: 0.7464 - val_loss: 1.7740 - val_accuracy: 0.7063\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 170s 4s/step - loss: 0.9931 - accuracy: 0.7565 - val_loss: 1.7963 - val_accuracy: 0.7026\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 168s 4s/step - loss: 0.9450 - accuracy: 0.7685 - val_loss: 1.7839 - val_accuracy: 0.7089\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 168s 4s/step - loss: 0.9006 - accuracy: 0.7796 - val_loss: 1.7940 - val_accuracy: 0.7051\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 169s 4s/step - loss: 0.8658 - accuracy: 0.7869 - val_loss: 1.7964 - val_accuracy: 0.7069\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 158s 4s/step - loss: 0.8286 - accuracy: 0.7969 - val_loss: 1.8031 - val_accuracy: 0.7139\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 167s 4s/step - loss: 0.7939 - accuracy: 0.8036 - val_loss: 1.8241 - val_accuracy: 0.7060\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 167s 4s/step - loss: 0.7524 - accuracy: 0.8175 - val_loss: 1.8192 - val_accuracy: 0.7122\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 157s 4s/step - loss: 0.7214 - accuracy: 0.8242 - val_loss: 1.8266 - val_accuracy: 0.7134\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, encoder_input_data, decoder_input_data, decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690468822925,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "HcmQ1WDOZ-KO"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"models/PD_Bidirectional_model_updated.h5\")\n",
    "model.save(\"models/PD_Bidirectional_model_updated.keras\")\n",
    "\n",
    "# Save the tokenizer\n",
    "with open(\"models/PD_Bidirectional_tokenizer_updated.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0NphPj2suk10cwPWKqLaa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
