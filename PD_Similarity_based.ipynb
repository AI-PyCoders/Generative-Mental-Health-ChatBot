{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6267e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918260f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient: Hello, Good morning doctor.\n",
      "doctor: Good morning, how are you feeling today?\n",
      "\n",
      "patient: I've been feeling quite anxious lately, it's been hard to relax.\n",
      "doctor: I see. Can you tell me more about what might be causing this anxiety?\n",
      "\n",
      "patient: I think it's mainly related to my job and the pressure I'm under.\n",
      "doctor: Stress at work can definitely take a toll on our well-being. Tell me about your job and the specific challenges you're facing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_conversations_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversations = file.readlines()\n",
    "    return conversations\n",
    "\n",
    "def process_text(text):\n",
    "    return text.replace('Patient: ', '').replace('Doctor: ', '')\n",
    "\n",
    "def format_data(conversations):\n",
    "    dialogue_pairs = []\n",
    "\n",
    "    patient_text = None\n",
    "    for line in conversations:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"Patient:\"):\n",
    "            patient_text = process_text(line)\n",
    "        elif line.startswith(\"Doctor:\") and patient_text is not None:\n",
    "            doctor_text = process_text(line)\n",
    "            dialogue_pairs.append([patient_text, doctor_text])\n",
    "\n",
    "    return dialogue_pairs\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'datasets/patient-doctor.txt'\n",
    "conversations = read_conversations_from_file(file_path)\n",
    "data = format_data(conversations)\n",
    "for i,o in data[:3]:\n",
    "    print('patient:',i)\n",
    "    print('doctor:',o)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec9b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase conversion\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove multiple dots\n",
    "    text = re.sub('\\.{2,}', ' ', text)\n",
    "\n",
    "    # Replace multiple whitespaces with a single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # Removing extra characters\n",
    "    pattern = r'[^A-Za-z0-9.\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = tokens.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    \n",
    "    # Rejoin tokens into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "def find_best_match(question):\n",
    "    best_match = None\n",
    "    best_match_score = 0\n",
    "\n",
    "    for pair in data:\n",
    "        current_score = similarity_score(question, pair[0])\n",
    "        if current_score > best_match_score:\n",
    "            best_match = pair\n",
    "            best_match_score = current_score\n",
    "\n",
    "    return (\n",
    "        (best_match[1])\n",
    "        if best_match\n",
    "        else \"Sorry, I hope it gets better.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def similarity_score(question1, question2):\n",
    "    question1 = process_text(question1)\n",
    "    question2 = process_text(question2)\n",
    "    vectorizer = CountVectorizer().fit_transform([question1, question2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity = cosine_similarity(vectors[0].reshape(1, -1), vectors[1].reshape(1, -1))\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f429a709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:Hello\n",
      "Bot: Good day! How can I assist you today?\n",
      "User:I am feeling depressed.\n",
      "Bot: I'm here to assist you. Please share your thoughts.\n",
      "User:What can I do to get rid of this anxiety\n",
      "Bot: Healing is possible, and I'm here to guide you towards a brighter and more fulfilling future.\n",
      "User:okay, thanks.\n",
      "Bot: It's alright. We'll figure it out together. Please open up.\n",
      "User:I am feeling sad\n",
      "Bot: Depression can be challenging, but remember that it's treatable. We'll work on strategies to lift your mood and find joy again.\n",
      "User:\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"User:\")\n",
    "while inp != '':\n",
    "    print(\"Bot:\",find_best_match(inp))\n",
    "    inp = input(\"User:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
