{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3402,
     "status": "ok",
     "timestamp": 1690361536776,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "I9Ivd53pZKzM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1690361607964,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "phybv4ljZhGs",
    "outputId": "bacafa95-5605-477e-bb8d-348cd221db29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>&lt;start&gt; i'm fine. how about yourself? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>&lt;start&gt; i'm pretty good. thanks for asking. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>&lt;start&gt; no problem. so how have you been? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>&lt;start&gt; i've been great. what about you? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>&lt;start&gt; i've been good. i'm in school right no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>that's a good question. maybe it's not old age.</td>\n",
       "      <td>&lt;start&gt; are you right-handed? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>are you right-handed?</td>\n",
       "      <td>&lt;start&gt; yes. all my life. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>yes. all my life.</td>\n",
       "      <td>&lt;start&gt; you're wearing out your right hand. st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>you're wearing out your right hand. stop using...</td>\n",
       "      <td>&lt;start&gt; but i do all my writing with my right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>but i do all my writing with my right hand.</td>\n",
       "      <td>&lt;start&gt; start typing instead. that way your le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3725 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                                hi, how are you doing?   \n",
       "1                         i'm fine. how about yourself?   \n",
       "2                   i'm pretty good. thanks for asking.   \n",
       "3                     no problem. so how have you been?   \n",
       "4                      i've been great. what about you?   \n",
       "...                                                 ...   \n",
       "3720    that's a good question. maybe it's not old age.   \n",
       "3721                              are you right-handed?   \n",
       "3722                                  yes. all my life.   \n",
       "3723  you're wearing out your right hand. stop using...   \n",
       "3724        but i do all my writing with my right hand.   \n",
       "\n",
       "                                                 answer  \n",
       "0           <start> i'm fine. how about yourself? <end>  \n",
       "1     <start> i'm pretty good. thanks for asking. <end>  \n",
       "2       <start> no problem. so how have you been? <end>  \n",
       "3        <start> i've been great. what about you? <end>  \n",
       "4     <start> i've been good. i'm in school right no...  \n",
       "...                                                 ...  \n",
       "3720                <start> are you right-handed? <end>  \n",
       "3721                    <start> yes. all my life. <end>  \n",
       "3722  <start> you're wearing out your right hand. st...  \n",
       "3723  <start> but i do all my writing with my right ...  \n",
       "3724  <start> start typing instead. that way your le...  \n",
       "\n",
       "[3725 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/other_data/conversation.csv', index_col=0)\n",
    "df['answer'] = df['answer'].apply(lambda text: '<start> ' + str(text) + ' <end>')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1690361583847,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "0Zz843cYZow8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(input_texts, target_texts):\n",
    "    # Create a tokenizer and fit on the input and target texts\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(input_texts + target_texts)\n",
    "\n",
    "    # Convert input and target texts to sequences of integers\n",
    "    encoder_input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "    decoder_input_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "    # Calculate max sequence length\n",
    "    max_sequence_length = max(max(len(seq) for seq in encoder_input_sequences),\n",
    "                             max(len(seq) for seq in decoder_input_sequences))\n",
    "    print('max sequence length:', max_sequence_length)\n",
    "    # Pad sequences to have the same length\n",
    "    encoder_input_data = pad_sequences(encoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    decoder_input_data = pad_sequences(decoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "    # Shift target sequences by one time step and convert to one-hot encoding\n",
    "    decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "    decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
    "    decoder_target_data[:, -1] = tokenizer.word_index['<end>']\n",
    "\n",
    "    # Return preprocessed data and tokenizer\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1690361612562,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "hPmJB2geZtcX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sequence length: 21\n"
     ]
    }
   ],
   "source": [
    "input_texts = df['question'].astype(str).tolist()\n",
    "target_texts = df['answer'].astype(str).tolist()\n",
    "# Preprocess the data\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length = preprocess_data(\n",
    "    input_texts, target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1690361638080,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "cn5R2MR2ZvhN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Input, Embedding, Bidirectional, LSTM, Dense, Attention, Concatenate, Dot, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_model(vocab_size, embedding_dim, hidden_dim, max_sequence_length):\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_dim, return_sequences=True, return_state=True))\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_state_h = Concatenate()([forward_h, backward_h])\n",
    "    encoder_state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_dim*2, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])\n",
    "    decoder_outputs = Dropout(0.2)(decoder_outputs)  # Adding Dropout layer for regularization\n",
    "\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention = Dot(axes=[2, 2])\n",
    "    attention_scores = attention([decoder_outputs, encoder_outputs])\n",
    "    attention_weights = Activation('softmax')(attention_scores)\n",
    "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
    "\n",
    "    # Concatenate the context vector and decoder outputs\n",
    "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "\n",
    "    # Dense layer for generating the final output\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, encoder_input_data, decoder_input_data, decoder_target_data, batch_size, epochs, validation_split):\n",
    "     # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # train the model\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split,\n",
    "              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4982064,
     "status": "ok",
     "timestamp": 1690366634327,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "hRR4mnhVZ6rb",
    "outputId": "a3ec5a75-812a-4c00-8131-eb92e9a2e299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  4042\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 21)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 21, 256)              1034752   ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 21)]                 0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  [(None, 21, 512),            1050624   ['embedding_3[0][0]']         \n",
      " onal)                        (None, 256),                                                        \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 21, 256)              1034752   ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 512)                  0         ['bidirectional_2[0][1]',     \n",
      " )                                                                   'bidirectional_2[0][3]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 512)                  0         ['bidirectional_2[0][2]',     \n",
      " )                                                                   'bidirectional_2[0][4]']     \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, 21, 512),            1574912   ['embedding_4[0][0]',         \n",
      "                              (None, 512),                           'concatenate_3[0][0]',       \n",
      "                              (None, 512)]                           'concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 21, 512)              0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                 (None, 21, 21)               0         ['dropout_1[0][0]',           \n",
      "                                                                     'bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 21, 21)               0         ['dot_2[0][0]']               \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                 (None, 21, 512)              0         ['activation_1[0][0]',        \n",
      "                                                                     'bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 21, 1024)             0         ['dot_3[0][0]',               \n",
      " )                                                                   'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 21, 4042)             4143050   ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8838090 (33.71 MB)\n",
      "Trainable params: 8838090 (33.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 74s 684ms/step - loss: 5.8840 - accuracy: 0.2033 - val_loss: 5.4084 - val_accuracy: 0.2448\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 54s 570ms/step - loss: 4.8576 - accuracy: 0.2638 - val_loss: 5.3223 - val_accuracy: 0.2468\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 54s 572ms/step - loss: 4.5680 - accuracy: 0.2790 - val_loss: 5.3088 - val_accuracy: 0.2711\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 54s 572ms/step - loss: 4.3192 - accuracy: 0.3024 - val_loss: 5.3163 - val_accuracy: 0.2776\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 54s 575ms/step - loss: 4.0779 - accuracy: 0.3180 - val_loss: 5.3737 - val_accuracy: 0.2766\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 54s 572ms/step - loss: 3.8190 - accuracy: 0.3329 - val_loss: 5.4372 - val_accuracy: 0.2710\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 55s 581ms/step - loss: 3.5297 - accuracy: 0.3505 - val_loss: 5.5442 - val_accuracy: 0.2589\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 54s 574ms/step - loss: 3.2067 - accuracy: 0.3743 - val_loss: 5.6982 - val_accuracy: 0.2553\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocab size: ', vocab_size)\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "validation_split = 0.2\n",
    "\n",
    "model = create_model(vocab_size, embedding_dim, hidden_units, max_sequence_length)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, encoder_input_data, decoder_input_data, decoder_target_data, batch_size, epochs, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1690366687775,
     "user": {
      "displayName": "Mukul Bisht",
      "userId": "00171967760273142052"
     },
     "user_tz": 240
    },
    "id": "HcmQ1WDOZ-KO"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"models/Conv_Bidirectional_model.h5\")\n",
    "\n",
    "# Save the tokenizer\n",
    "with open(\"models/Conv_Bidirectional_tokenizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMkvk/9zJjWh9CgbvSbFIq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
