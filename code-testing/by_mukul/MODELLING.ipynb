{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abb3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06375fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello good morning doctor</td>\n",
       "      <td>&lt;start&gt; good morning how are you feeling today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive been feeling quite anxious lately its been...</td>\n",
       "      <td>&lt;start&gt; i see can you tell me more about what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think its mainly related to my job and the p...</td>\n",
       "      <td>&lt;start&gt; stress at work can definitely take a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a highly demanding environment and i...</td>\n",
       "      <td>&lt;start&gt; that sounds tough do you have any supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i try to talk to my friends but they dont alwa...</td>\n",
       "      <td>&lt;start&gt; having a strong support system is impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>i find it difficult to cope and the grief ofte...</td>\n",
       "      <td>&lt;start&gt; coping with grief can be emotionally e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>i havent been very open about my struggles as ...</td>\n",
       "      <td>&lt;start&gt; its common to feel hesitant about shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>lately i havent been actively practicing selfc...</td>\n",
       "      <td>&lt;start&gt; practicing selfcompassion and engaging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>i havent sought professional help yet im unsur...</td>\n",
       "      <td>&lt;start&gt; seeking professional help such as ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>thank you doctor your guidance is greatly appr...</td>\n",
       "      <td>&lt;start&gt; youre welcome its my role to provide s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Patient  \\\n",
       "0                             hello good morning doctor   \n",
       "1     ive been feeling quite anxious lately its been...   \n",
       "2     i think its mainly related to my job and the p...   \n",
       "3     i work in a highly demanding environment and i...   \n",
       "4     i try to talk to my friends but they dont alwa...   \n",
       "...                                                 ...   \n",
       "1503  i find it difficult to cope and the grief ofte...   \n",
       "1504  i havent been very open about my struggles as ...   \n",
       "1505  lately i havent been actively practicing selfc...   \n",
       "1506  i havent sought professional help yet im unsur...   \n",
       "1507  thank you doctor your guidance is greatly appr...   \n",
       "\n",
       "                                                 Doctor  \n",
       "0     <start> good morning how are you feeling today...  \n",
       "1     <start> i see can you tell me more about what ...  \n",
       "2     <start> stress at work can definitely take a t...  \n",
       "3     <start> that sounds tough do you have any supp...  \n",
       "4     <start> having a strong support system is impo...  \n",
       "...                                                 ...  \n",
       "1503  <start> coping with grief can be emotionally e...  \n",
       "1504  <start> its common to feel hesitant about shar...  \n",
       "1505  <start> practicing selfcompassion and engaging...  \n",
       "1506  <start> seeking professional help such as ther...  \n",
       "1507  <start> youre welcome its my role to provide s...  \n",
       "\n",
       "[1508 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/patient-doctor.csv')\n",
    "df['Doctor'] = df['Doctor'].apply(lambda text: '<start> ' + text + ' <end>')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682531d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(input_texts, target_texts):\n",
    "    # Create a tokenizer and fit on the input and target texts\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(input_texts + target_texts)\n",
    "\n",
    "    # Convert input and target texts to sequences of integers\n",
    "    encoder_input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "    decoder_input_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "    \n",
    "    # Calculate max sequence length\n",
    "    max_sequence_length = max(max(len(seq) for seq in encoder_input_sequences),\n",
    "                             max(len(seq) for seq in decoder_input_sequences))\n",
    "    \n",
    "    # Pad sequences to have the same length\n",
    "    encoder_input_data = pad_sequences(encoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    decoder_input_data = pad_sequences(decoder_input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    # Shift target sequences by one time step and convert to one-hot encoding\n",
    "    decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "    decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
    "    decoder_target_data[:, -1] = tokenizer.word_index['<end>']\n",
    "    \n",
    "    # Return preprocessed data and tokenizer\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['Patient'].astype(str).tolist()\n",
    "target_texts = df['Doctor'].astype(str).tolist()\n",
    "# Preprocess the data\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, tokenizer, max_sequence_length = preprocess_data(\n",
    "    input_texts, target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Input, Embedding, Bidirectional, LSTM, Dense, Attention, Concatenate, Dot, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def create_model(vocab_size, embedding_dim, hidden_units, max_sequence_length):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
    "    decoder_outputs = Dropout(0.2)(decoder_outputs)  # Adding Dropout layer for regularization\n",
    "\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Dot(axes=[2, 2])\n",
    "    attention_scores = attention([decoder_outputs, encoder_outputs])\n",
    "    attention_weights = Activation('softmax')(attention_scores)\n",
    "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
    "\n",
    "    # Concatenate the context vector and decoder outputs\n",
    "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "\n",
    "    # Dense layer for generating the final output\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_2(vocab_size, embedding_dim, hidden_dim, max_sequence_length):\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)    \n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_dim, return_sequences=True, return_state=True))\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_state_h = Concatenate()([forward_h, backward_h])\n",
    "    encoder_state_c = Concatenate()([forward_c, backward_c])\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(hidden_dim*2, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])\n",
    "    decoder_outputs = Dropout(0.2)(decoder_outputs)  # Adding Dropout layer for regularization\n",
    "\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Dot(axes=[2, 2])\n",
    "    attention_scores = attention([decoder_outputs, encoder_outputs])\n",
    "    attention_weights = Activation('softmax')(attention_scores)\n",
    "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
    "\n",
    "    # Concatenate the context vector and decoder outputs\n",
    "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "\n",
    "    # Dense layer for generating the final output\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, encoder_input_data, decoder_input_data, decoder_target_data, batch_size, epochs, validation_split):\n",
    "     # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # train the model\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              validation_split=validation_split,\n",
    "              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd564c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocab size: ', vocab_size)\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 256\n",
    "hidden_units = 256\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "validation_split = 0.2\n",
    "\n",
    "model = create_model_2(vocab_size, embedding_dim, hidden_units, max_sequence_length)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, encoder_input_data, decoder_input_data, decoder_target_data, batch_size, epochs, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoder(model, input_sequence, tokenizer, beam_width, max_len):\n",
    "    # Initialize beam search\n",
    "    sequences = [[[], 0.0]]\n",
    "    end_token_index = tokenizer.word_index['<end>']\n",
    "\n",
    "    \n",
    "    # Iterate through each prediction step\n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        \n",
    "        # Generate candidates for each sequence\n",
    "        for seq, score in sequences:\n",
    "            if len(seq) > 0:\n",
    "                input_seq = pad_sequences([seq], maxlen=max_len)\n",
    "                pred = model.predict([input_sequence, input_seq])[0][-1]\n",
    "                top_scores_indices = np.argsort(pred)[-beam_width:]\n",
    "                \n",
    "                for index in top_scores_indices:\n",
    "                    candidate = [seq + [index], score + np.log(pred[index])]\n",
    "                    all_candidates.append(candidate)\n",
    "            else:\n",
    "                # Handle the initial empty sequence\n",
    "                pred = model.predict([input_sequence, np.zeros((1, max_len))])[0][-1]\n",
    "                top_scores_indices = np.argsort(pred)[-beam_width:]\n",
    "                \n",
    "                for index in top_scores_indices:\n",
    "                    candidate = [[index], score + np.log(pred[index])]\n",
    "                    all_candidates.append(candidate)\n",
    "        \n",
    "        # Select top-k candidates\n",
    "        ordered = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
    "        sequences = ordered[:beam_width]\n",
    "        \n",
    "        # Check if any sequence ends with the end token\n",
    "        end_flag = False\n",
    "        for seq, _ in sequences:\n",
    "            if seq[-1] == end_token_index:\n",
    "                end_flag = True\n",
    "                break\n",
    "        \n",
    "        if end_flag:\n",
    "            break\n",
    "    \n",
    "    # Get the sequence with the highest score\n",
    "    best_sequence = sequences[0][0]\n",
    "    \n",
    "    # Convert token indices to text\n",
    "    decoded_sequence = tokenizer.sequences_to_texts([best_sequence])[0]\n",
    "    \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response\n",
    "def generate_response(input_text, model, tokenizer):\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=50, padding='post')\n",
    "    decoded_sequence = beam_search_decoder(model, input_seq, tokenizer, beam_width=3, max_len=50)\n",
    "    return decoded_sequence\n",
    "\n",
    "print(\"Bot: Hi, I am a learning psychiatrist. ask me anything.\")\n",
    "input_text = \"I've noticed that my anxiety tends to escalate.\"\n",
    "while input_text != '':\n",
    "    response = generate_response(input_text, model, tokenizer)\n",
    "    print(\"Bot:\",  response)\n",
    "    input_text = input('User: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"models/PD_Attention_trained_model.h5\")\n",
    "\n",
    "# Save the tokenizer\n",
    "with open(\"models/PD_Attention_tokenizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
